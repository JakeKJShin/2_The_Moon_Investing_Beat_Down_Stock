{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "\n",
    "1. GET S&P 500 company info<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\jakek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from newsapi import NewsApiClient\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get S&P 500 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RHI</th>\n",
       "      <td>Robert Half</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Human Resource &amp; Employment Services</td>\n",
       "      <td>Menlo Park, California</td>\n",
       "      <td>2000-12-05</td>\n",
       "      <td>315213</td>\n",
       "      <td>1948</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROK</th>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Electrical Components &amp; Equipment</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1024478</td>\n",
       "      <td>1903</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROL</th>\n",
       "      <td>Rollins</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Environmental &amp; Facilities Services</td>\n",
       "      <td>Atlanta, Georgia</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>84839</td>\n",
       "      <td>1948</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROP</th>\n",
       "      <td>Roper</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Sarasota, Florida</td>\n",
       "      <td>2009-12-23</td>\n",
       "      <td>882835</td>\n",
       "      <td>1981</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROST</th>\n",
       "      <td>Ross</td>\n",
       "      <td>reports</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Apparel Retail</td>\n",
       "      <td>Dublin, California</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>745732</td>\n",
       "      <td>1982</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YUM</th>\n",
       "      <td>Yum! Brands</td>\n",
       "      <td>reports</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Louisville, Kentucky</td>\n",
       "      <td>1997-10-06</td>\n",
       "      <td>1041061</td>\n",
       "      <td>1997</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBRA</th>\n",
       "      <td>Zebra</td>\n",
       "      <td>reports</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Electronic Equipment &amp; Instruments</td>\n",
       "      <td>Lincolnshire, Illinois</td>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>877212</td>\n",
       "      <td>1969</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZBH</th>\n",
       "      <td>Zimmer Biomet</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Warsaw, Indiana</td>\n",
       "      <td>2001-08-07</td>\n",
       "      <td>1136869</td>\n",
       "      <td>1927</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZION</th>\n",
       "      <td>Zions Bancorp</td>\n",
       "      <td>reports</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Regional Banks</td>\n",
       "      <td>Salt Lake City, Utah</td>\n",
       "      <td>2001-06-22</td>\n",
       "      <td>109380</td>\n",
       "      <td>1873</td>\n",
       "      <td>Financials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTS</th>\n",
       "      <td>Zoetis</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Parsippany, New Jersey</td>\n",
       "      <td>2013-06-21</td>\n",
       "      <td>1555280</td>\n",
       "      <td>1952</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Security SEC filings             GICS Sector  \\\n",
       "Symbol                                                            \n",
       "RHI             Robert Half     reports             Industrials   \n",
       "ROK     Rockwell Automation     reports             Industrials   \n",
       "ROL                 Rollins     reports             Industrials   \n",
       "ROP                   Roper     reports             Industrials   \n",
       "ROST                   Ross     reports  Consumer Discretionary   \n",
       "...                     ...         ...                     ...   \n",
       "YUM             Yum! Brands     reports  Consumer Discretionary   \n",
       "ZBRA                  Zebra     reports  Information Technology   \n",
       "ZBH           Zimmer Biomet     reports             Health Care   \n",
       "ZION          Zions Bancorp     reports              Financials   \n",
       "ZTS                  Zoetis     reports             Health Care   \n",
       "\n",
       "                           GICS Sub-Industry   Headquarters Location  \\\n",
       "Symbol                                                                 \n",
       "RHI     Human Resource & Employment Services  Menlo Park, California   \n",
       "ROK        Electrical Components & Equipment    Milwaukee, Wisconsin   \n",
       "ROL      Environmental & Facilities Services        Atlanta, Georgia   \n",
       "ROP                 Industrial Conglomerates       Sarasota, Florida   \n",
       "ROST                          Apparel Retail      Dublin, California   \n",
       "...                                      ...                     ...   \n",
       "YUM                              Restaurants    Louisville, Kentucky   \n",
       "ZBRA      Electronic Equipment & Instruments  Lincolnshire, Illinois   \n",
       "ZBH                    Health Care Equipment         Warsaw, Indiana   \n",
       "ZION                          Regional Banks    Salt Lake City, Utah   \n",
       "ZTS                          Pharmaceuticals  Parsippany, New Jersey   \n",
       "\n",
       "       Date first added      CIK Founded       GICS Sub Industry  \n",
       "Symbol                                                            \n",
       "RHI          2000-12-05   315213    1948             Industrials  \n",
       "ROK                 NaN  1024478    1903             Industrials  \n",
       "ROL          2018-10-01    84839    1948             Industrials  \n",
       "ROP          2009-12-23   882835    1981             Industrials  \n",
       "ROST         2009-12-21   745732    1982  Consumer Discretionary  \n",
       "...                 ...      ...     ...                     ...  \n",
       "YUM          1997-10-06  1041061    1997  Consumer Discretionary  \n",
       "ZBRA         2019-12-23   877212    1969  Information Technology  \n",
       "ZBH          2001-08-07  1136869    1927             Health Care  \n",
       "ZION         2001-06-22   109380    1873              Financials  \n",
       "ZTS          2013-06-21  1555280    1952             Health Care  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get table of the S&P 500 tickers, CIK, and industry from Wikipedia\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "cik_df = pd.read_html(wiki_url,header=0,index_col=0)[0]\n",
    "cik_df['GICS Sector'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df['GICS Sub Industry'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMM',\n",
       " 'AOS',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ABMD',\n",
       " 'ACN',\n",
       " 'ATVI',\n",
       " 'ADM',\n",
       " 'ADBE',\n",
       " 'ADP',\n",
       " 'AAP',\n",
       " 'AES',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'AIG',\n",
       " 'APD',\n",
       " 'AKAM',\n",
       " 'ALK',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOGL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMZN',\n",
       " 'AMCR',\n",
       " 'AMD',\n",
       " 'AEE',\n",
       " 'AAL',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'ABC',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'ADI',\n",
       " 'ANSS',\n",
       " 'ANTM',\n",
       " 'AON',\n",
       " 'APA',\n",
       " 'AAPL',\n",
       " 'AMAT',\n",
       " 'APTV',\n",
       " 'ANET',\n",
       " 'AIZ',\n",
       " 'T',\n",
       " 'ATO',\n",
       " 'ADSK',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'BKR',\n",
       " 'BLL',\n",
       " 'BAC',\n",
       " 'BBWI',\n",
       " 'BAX',\n",
       " 'BDX',\n",
       " 'WRB',\n",
       " 'BRK.B',\n",
       " 'BBY',\n",
       " 'BIO',\n",
       " 'TECH',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'BK',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BWA',\n",
       " 'BXP',\n",
       " 'BSX',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BRO',\n",
       " 'BF.B',\n",
       " 'CHRW',\n",
       " 'CDNS',\n",
       " 'CZR',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CAH',\n",
       " 'KMX',\n",
       " 'CCL',\n",
       " 'CARR',\n",
       " 'CTLT',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CDW',\n",
       " 'CE',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CDAY',\n",
       " 'CERN',\n",
       " 'CF',\n",
       " 'CRL',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CTXS',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CMA',\n",
       " 'CAG',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'CEG',\n",
       " 'COO',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'CTVA',\n",
       " 'COST',\n",
       " 'CTRA',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHI',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DVA',\n",
       " 'DE',\n",
       " 'DAL',\n",
       " 'XRAY',\n",
       " 'DVN',\n",
       " 'DXCM',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DFS',\n",
       " 'DISCA',\n",
       " 'DISCK',\n",
       " 'DISH',\n",
       " 'DIS',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DPZ',\n",
       " 'DOV',\n",
       " 'DOW',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DRE',\n",
       " 'DD',\n",
       " 'DXC',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'EMR',\n",
       " 'ENPH',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EPAM',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'ETSY',\n",
       " 'RE',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'EXC',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FDS',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FITB',\n",
       " 'FRC',\n",
       " 'FE',\n",
       " 'FIS',\n",
       " 'FISV',\n",
       " 'FLT',\n",
       " 'FMC',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FBHS',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'AJG',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GE',\n",
       " 'GNRC',\n",
       " 'GD',\n",
       " 'GIS',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GL',\n",
       " 'GPN',\n",
       " 'GM',\n",
       " 'GS',\n",
       " 'GWW',\n",
       " 'HAL',\n",
       " 'HIG',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'PEAK',\n",
       " 'HSIC',\n",
       " 'HSY',\n",
       " 'HES',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HWM',\n",
       " 'HPQ',\n",
       " 'HUM',\n",
       " 'HII',\n",
       " 'HBAN',\n",
       " 'IEX',\n",
       " 'IDXX',\n",
       " 'ITW',\n",
       " 'ILMN',\n",
       " 'INCY',\n",
       " 'IR',\n",
       " 'INTC',\n",
       " 'ICE',\n",
       " 'IBM',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'IFF',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'IPGP',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JBHT',\n",
       " 'JKHY',\n",
       " 'J',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'JNPR',\n",
       " 'K',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KLAC',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LHX',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LVS',\n",
       " 'LDOS',\n",
       " 'LEN',\n",
       " 'LLY',\n",
       " 'LNC',\n",
       " 'LIN',\n",
       " 'LYV',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LUMN',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'MKTX',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MTCH',\n",
       " 'MKC',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'FB',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MSFT',\n",
       " 'MAA',\n",
       " 'MRNA',\n",
       " 'MHK',\n",
       " 'MOH',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MPWR',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MOS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'NDAQ',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NWL',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NLSN',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NDSN',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NLOK',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NVR',\n",
       " 'NXPI',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'ODFL',\n",
       " 'OMC',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'OGN',\n",
       " 'OTIS',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PARA',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PAYC',\n",
       " 'PYPL',\n",
       " 'PENN',\n",
       " 'PNR',\n",
       " 'PBCT',\n",
       " 'PEP',\n",
       " 'PKI',\n",
       " 'PFE',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PXD',\n",
       " 'PNC',\n",
       " 'POOL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PEG',\n",
       " 'PTC',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'PVH',\n",
       " 'QRVO',\n",
       " 'PWR',\n",
       " 'QCOM',\n",
       " 'DGX',\n",
       " 'RL',\n",
       " 'RJF',\n",
       " 'RTX',\n",
       " 'O',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RHI',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'SPGI',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SEE',\n",
       " 'SRE',\n",
       " 'NOW',\n",
       " 'SHW',\n",
       " 'SBNY',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SJM',\n",
       " 'SNA',\n",
       " 'SEDG',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'STE',\n",
       " 'SYK',\n",
       " 'SIVB',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TMUS',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'TDY',\n",
       " 'TFX',\n",
       " 'TER',\n",
       " 'TSLA',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'TMO',\n",
       " 'TJX',\n",
       " 'TSCO',\n",
       " 'TT',\n",
       " 'TDG',\n",
       " 'TRV',\n",
       " 'TRMB',\n",
       " 'TFC',\n",
       " 'TWTR',\n",
       " 'TYL',\n",
       " 'TSN',\n",
       " 'USB',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'UAA',\n",
       " 'UA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UNH',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UHS',\n",
       " 'VLO',\n",
       " 'VTR',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VFC',\n",
       " 'VTRS',\n",
       " 'V',\n",
       " 'VNO',\n",
       " 'VMC',\n",
       " 'WAB',\n",
       " 'WMT',\n",
       " 'WBA',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WST',\n",
       " 'WDC',\n",
       " 'WRK',\n",
       " 'WY',\n",
       " 'WHR',\n",
       " 'WMB',\n",
       " 'WTW',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBRA',\n",
       " 'ZBH',\n",
       " 'ZION',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol_list = cik_df.index.tolist()\n",
    "symbol_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_1 = ' '.join([symbol_list[i] for i in range(0,50)]).replace(\" \", \" OR \")\n",
    "string_2 = ' '.join([symbol_list[i] for i in range(50,100)]).replace(\" \", \" OR \")\n",
    "string_3 = ' '.join([symbol_list[i] for i in range(100,150)]).replace(\" \", \" OR \")\n",
    "string_4 = ' '.join([symbol_list[i] for i in range(150,200)]).replace(\" \", \" OR \")\n",
    "string_5 = ' '.join([symbol_list[i] for i in range(200,250)]).replace(\" \", \" OR \")\n",
    "string_6 = ' '.join([symbol_list[i] for i in range(250,300)]).replace(\" \", \" OR \")\n",
    "string_7 = ' '.join([symbol_list[i] for i in range(300,350)]).replace(\" \", \" OR \")\n",
    "string_8 = ' '.join([symbol_list[i] for i in range(350,400)]).replace(\" \", \" OR \")\n",
    "string_9 = ' '.join([symbol_list[i] for i in range(400,450)]).replace(\" \", \" OR \")\n",
    "string_10 = ' '.join([symbol_list[i] for i in range(450,500)]).replace(\" \", \" OR \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "load_dotenv()\n",
    "newsapi = NewsApiClient(api_key=os.environ[\"NEWS_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "headlines = newsapi.get_everything(\n",
    "    q=,\n",
    "    language=\"en\",\n",
    "    page_size=100,\n",
    "    sort_by=\"relevancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_1 = newsapi.get_everything(\n",
    "    q = string_1,\n",
    "    language=\"en\",\n",
    "    page_size=100,\n",
    "    sort_by=\"relevancy\"\n",
    ")\n",
    "\n",
    "headlines_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3M CompanyMMM recently announced a 0.7% hike i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.881</td>\n",
       "      <td>Monday, February 14, 2022\\r\\nThe Zacks Researc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>For Immediate Release\\r\\nChicago, IL February ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>Making its debut on 05/27/2011, smart beta exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5574</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.909</td>\n",
       "      <td>Wall Street put up a moderate show last week w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>For Immediate Release\\r\\nChicago, IL February ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.922</td>\n",
       "      <td>Its a familiar scene. Youre perched in front o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.7764</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.708</td>\n",
       "      <td>Cressida Dick absolutely despised Line of Duty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.8190</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.755</td>\n",
       "      <td>Mmm, cashmere. So soft and fluffy, right? As w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>For many Russians, it was an unfamiliar sight ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound  Positive  Negative  Neutral  \\\n",
       "0    0.0000     0.000     0.000    1.000   \n",
       "1    0.6369     0.119     0.000    0.881   \n",
       "2    0.0000     0.000     0.000    1.000   \n",
       "3    0.7184     0.167     0.000    0.833   \n",
       "4    0.5574     0.091     0.000    0.909   \n",
       "5    0.0000     0.000     0.000    1.000   \n",
       "6    0.4939     0.078     0.000    0.922   \n",
       "7   -0.7764     0.066     0.226    0.708   \n",
       "8   -0.8190     0.041     0.204    0.755   \n",
       "9    0.0000     0.000     0.000    1.000   \n",
       "\n",
       "                                                Text  \n",
       "0  3M CompanyMMM recently announced a 0.7% hike i...  \n",
       "1  Monday, February 14, 2022\\r\\nThe Zacks Researc...  \n",
       "2  For Immediate Release\\r\\nChicago, IL February ...  \n",
       "3  Making its debut on 05/27/2011, smart beta exc...  \n",
       "4  Wall Street put up a moderate show last week w...  \n",
       "5  For Immediate Release\\r\\nChicago, IL February ...  \n",
       "6  Its a familiar scene. Youre perched in front o...  \n",
       "7  Cressida Dick absolutely despised Line of Duty...  \n",
       "8  Mmm, cashmere. So soft and fluffy, right? As w...  \n",
       "9  For many Russians, it was an unfamiliar sight ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the S&p 500 sentiment scores DataFrame\n",
    "sentiments = []\n",
    "\n",
    "for article in headlines[\"articles\"]:\n",
    "    try:\n",
    "        \n",
    "        text = article[\"content\"]\n",
    "        date = article[\"publishedAt\"][:10]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        sentiments.append({\n",
    "            \n",
    "            \n",
    "            \"Compound\": compound,\n",
    "            \"Positive\": pos,\n",
    "            \"Negative\": neg,\n",
    "            \"Neutral\": neu,\n",
    "            \"Text\": text\n",
    "            \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Compound\", \"Positive\", \"Negative\", \"Neutral\",\"Text\"]\n",
    "df = df[cols]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.152980</td>\n",
       "      <td>0.075890</td>\n",
       "      <td>0.039680</td>\n",
       "      <td>0.88446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.424164</td>\n",
       "      <td>0.080849</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>0.10654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.819000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.90800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.068250</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Compound    Positive    Negative    Neutral\n",
       "count  100.000000  100.000000  100.000000  100.00000\n",
       "mean     0.152980    0.075890    0.039680    0.88446\n",
       "std      0.424164    0.080849    0.059685    0.10654\n",
       "min     -0.819000    0.000000    0.000000    0.60400\n",
       "25%      0.000000    0.000000    0.000000    0.80375\n",
       "50%      0.000000    0.064000    0.000000    0.90800\n",
       "75%      0.510600    0.132000    0.068250    1.00000\n",
       "max      0.910000    0.314000    0.234000    1.00000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the lemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Expand the default stopwords list if necessary\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    \n",
    "    # Remove the punctuation from text\n",
    "    \n",
    "    regex = re.compile(\"[^a-zA-Z ]\")\n",
    "   \n",
    "    # Create a tokenized list of the words\n",
    "    re_clean = regex.sub('', text)\n",
    "    words = word_tokenize(re_clean)\n",
    "    words = word_tokenize(re_clean)\n",
    "    words = word_tokenize(re_clean.lower())\n",
    "    \n",
    "    # Lemmatize words into root words\n",
    "    lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "   \n",
    "    # Convert the words to lowercase\n",
    "    words = [word for word in words if word not in sw]\n",
    "    \n",
    "    # Remove the stop words\n",
    "   \n",
    "    return lem\n",
    "\n",
    "tokenizer(df.iloc[0]['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['Text'].apply(tokenizer)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(df):\n",
    "    tokens = []\n",
    "    for i in df['tokens']:\n",
    "        tokens.extend(i)\n",
    "    return tokens\n",
    "\n",
    "tokens = get_token(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_counter(tokens, N):\n",
    "    words_count = dict(Counter(ngrams(tokens, n=2)))\n",
    "    return words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function token_count generates the top 10 words for a given stock\n",
    "def token_count(tokens, N=3):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    return Counter(tokens).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count(tokens, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['Text'])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a title to the document\n",
    "doc.user_data[\"title\"] = \"NER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "org_list = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'ORG':\n",
    "        org_list.append(ent.text)\n",
    "\n",
    "org_list = Counter(org_list).most_common(100)\n",
    "\n",
    "df_org = pd.DataFrame(org_list, columns = ['text', 'count'])\n",
    "\n",
    "df_org.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Reuters as it is a publisher\n",
    "df_org = df_org.iloc[2:]\n",
    "df_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = newsapi.get_everything(\n",
    "    q=\"Polen\" \"\",\n",
    "    language=\"en\",\n",
    "    page_size=100,\n",
    "    sort_by=\"relevancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Polen sentiment scores DataFrame\n",
    "sentiments = []\n",
    "\n",
    "for article in headlines[\"articles\"]:\n",
    "    try:\n",
    "        \n",
    "        text = article[\"content\"]\n",
    "        date = article[\"publishedAt\"][:10]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        sentiments.append({\n",
    "            \n",
    "            \n",
    "            \"Compound\": compound,\n",
    "            \"Positive\": pos,\n",
    "            \"Negative\": neg,\n",
    "            \"Neutral\": neu,\n",
    "            \"Text\": text\n",
    "            \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "df_polen = pd.DataFrame(sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Compound\", \"Positive\", \"Negative\", \"Neutral\",\"Text\"]\n",
    "df_polen = df[cols]\n",
    "\n",
    "df_polen.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_polen.describe()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "457bfd66bc83167280522f0979df4544bbf298b22f7b001b0d6e3acbe142422c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
