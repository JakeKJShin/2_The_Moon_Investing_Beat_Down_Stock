{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Straw\n",
      "[nltk_data]     Hat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from requests_oauthlib import OAuth1Session\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from pathlib import Path\n",
    "import tweepy as tw\n",
    "from argparse import Namespace\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=os.environ.get(\"TWITTER_API_KEY\")\n",
    "consumer_secret=os.environ.get(\"TWITTER_SECERET_API_KEY\")\n",
    "access_token=os.environ.get(\"ACCESS_TOKEN\")\n",
    "access_token_secret=os.environ.get(\"ACCESS_TOKEN_SECRET\")\n",
    "bearer_token =os.environ.get(\"TWITTER_BEARER_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "client = tw.Client( bearer_token, \n",
    "                        consumer_key, \n",
    "                        consumer_secret, \n",
    "                        access_token, \n",
    "                        access_token_secret, \n",
    "                        return_type = requests.Response,\n",
    "                        wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5476333d75d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m tweets = client.search_recent_tweets(query=query, \n\u001b[0;32m      6\u001b[0m                                     \u001b[0mtweet_fields\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'author_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'created_at'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                                      max_results=100)\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Bootcamp\\envs\\dev\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36msearch_recent_tweets\u001b[1;34m(self, query, user_auth, **params)\u001b[0m\n\u001b[0;32m    912\u001b[0m                 \u001b[1;34m\"since_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sort_order\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"start_time\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tweet.fields\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;34m\"until_id\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user.fields\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m             ), data_type=Tweet, user_auth=user_auth\n\u001b[0m\u001b[0;32m    915\u001b[0m         )\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bootcamp\\envs\\dev\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         response = self.request(method, route, params=request_params,\n\u001b[1;32m--> 119\u001b[1;33m                                 json=json, user_auth=user_auth)\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Bootcamp\\envs\\dev\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mBadRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m401\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m403\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnauthorized\u001b[0m: 401 Unauthorized"
     ]
    }
   ],
   "source": [
    "# Define query\n",
    "query = 'from:zerohedge -is:retweet'\n",
    "\n",
    "# get max. 10 tweets\n",
    "tweets = client.search_recent_tweets(query=query, \n",
    "                                    tweet_fields=['author_id', 'created_at'],\n",
    "                                     max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as dictionary\n",
    "tweets_dict = tweets.json() \n",
    "\n",
    "# Extract \"data\" value from dictionary\n",
    "tweets_data = tweets_dict['data'] \n",
    "\n",
    "# Transform to pandas Dataframe\n",
    "df_1 = pd.json_normalize(tweets_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twitter API only limited to 7 days of feeds\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('tweets1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second tweet collection \n",
    "# Define query\n",
    "query = 'from:InvestorsLive -is:retweet'\n",
    "\n",
    "# get max. 10 tweets\n",
    "tweets2 = client.search_recent_tweets(query=query, \n",
    "                                    tweet_fields=['author_id', 'created_at'],\n",
    "                                     max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as dictionary\n",
    "tweets_dict2 = tweets2.json() \n",
    "\n",
    "# Extract \"data\" value from dictionary\n",
    "tweets_data2 = tweets_dict2['data'] \n",
    "\n",
    "# Transform to pandas Dataframe\n",
    "df_2 = pd.json_normalize(tweets_data2) \n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.to_csv('tweets2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Third tweet collection \n",
    "# Define query\n",
    "query = 'from:markflowchatter -is:retweet'\n",
    "\n",
    "# get max tweets\n",
    "tweets3 = client.search_recent_tweets(query=query, \n",
    "                                    tweet_fields=['author_id', 'created_at'],\n",
    "                                     max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as dictionary\n",
    "tweets_dict3 = tweets3.json() \n",
    "\n",
    "# Extract \"data\" value from dictionary\n",
    "tweets_data3 = tweets_dict3['data'] \n",
    "\n",
    "# Transform to pandas Dataframe\n",
    "df_3 = pd.json_normalize(tweets_data3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.to_csv('tweets3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fourth tweet collection \n",
    "# Define query\n",
    "query = 'from:OptionsHawk -is:retweet'\n",
    "\n",
    "# get max. 10 tweets\n",
    "tweets4 = client.search_recent_tweets(query=query, \n",
    "                                    tweet_fields=['author_id', 'created_at'],\n",
    "                                     max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as dictionary\n",
    "tweets_dict4 = tweets4.json() \n",
    "\n",
    "# Extract \"data\" value from dictionary\n",
    "tweets_data4 = tweets_dict4['data'] \n",
    "\n",
    "# Transform to pandas Dataframe\n",
    "df_4 = pd.json_normalize(tweets_data4) \n",
    "\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_1,df_2,df_3,df_4])\n",
    "#df_total[df_total['$'].replace(\"DOLLARS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe of all tweets with \"$\"\n",
    "df_scrub = df_total[df_total['text'].str.contains(\"$\", regex=False)]\n",
    "df_scrub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df_total.strings('positive_tweets.json')\n",
    "negative = df_total.strings('negative_tweets.json')\n",
    "all_tweets = df_total.strings(\"tweets.20150430-223406.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment scores\n",
    "tw_sentiment = Namespace(\n",
    "    positive = 1,\n",
    "    negative = 0,\n",
    "    decode = {\n",
    "        1: \"positive\",\n",
    "        0: \"negative\"\n",
    "    },\n",
    "    encode = {\n",
    "        \"positive\": 1,\n",
    "        \"negative\": 0,\n",
    "    }\n",
    ")\n",
    "positive_labels = [tw_sentiment.positive] * len(positive)\n",
    "negative_labels = [tw_sentiment.negative] * len(negative)\n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = positive_labels + negative_labels\n",
    "tweets = positive + negative\n",
    "\n",
    "print(f\"Labels: {len(labels):,}\")\n",
    "print(f\"tweets: {len(tweets):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_df = pd.DataFrame(tw_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"text\", \"compound\", \"positive\", \"neutral\", \"negative\"]\n",
    "tw_df = tw_df[cols]\n",
    "tw_df = tw_df.sort_values('compound', ascending = False)\n",
    "tw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 tickers with highest compound sentiment analysis \n",
    "## ISPO, HYMC, CMG, GFAI and DATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 tickers with lowest compound sentiment analysis \n",
    "## NVDA , GFAI , CMG, OLLI  and S&P "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "457bfd66bc83167280522f0979df4544bbf298b22f7b001b0d6e3acbe142422c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
