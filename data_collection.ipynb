{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "\n",
    "1. GET S&P 500 company info<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Straw\n",
      "[nltk_data]     Hat\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "from newsapi import NewsApiClient\n",
    "from pathlib import Path\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "class SEC_Extractor:\n",
    "    def get_doc_links(cik,ticker):\n",
    "        try:\n",
    "            base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "            inputted_cik = cik\n",
    "            payload = {\n",
    "                \"action\" : \"getcompany\",\n",
    "                \"CIK\" : inputted_cik,\n",
    "                \"type\" : \"8-K\",\n",
    "                \"output\":\"xml\",\n",
    "                \"dateb\" : \"20180401\",\n",
    "            }\n",
    "            sec_response = requests.get(url=base_url,params=payload)\n",
    "            soup = BeautifulSoup(sec_response.text,'lxml')\n",
    "            url_list = soup.findAll('filinghref')\n",
    "            html_list = []\n",
    "            # Get html version of links\n",
    "            for link in url_list:\n",
    "                link = link.string\n",
    "                if link.split(\".\")[len(link.split(\".\"))-1] == 'htm':\n",
    "                    txtlink = link + \"l\"\n",
    "                    html_list.append(txtlink)\n",
    "\n",
    "            doc_list = []\n",
    "            doc_name_list = []\n",
    "            # Get links for txt versions of files\n",
    "            for k in range(len(html_list)):\n",
    "                txt_doc = html_list[k].replace(\"-index.html\",\".txt\")\n",
    "                doc_name = txt_doc.split(\"/\")[-1]\n",
    "                doc_list.append(txt_doc)\n",
    "                doc_name_list.append(doc_name)\n",
    "                # Create dataframe of CIK, doc name, and txt link\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                \"cik\" : [cik]*len(html_list),\n",
    "                \"ticker\" : [ticker]*len(html_list),\n",
    "                \"txt_link\" : doc_list,\n",
    "                \"doc_name\": doc_name_list\n",
    "                }\n",
    "            )\n",
    "        except requests.exceptions.ConnectionError:\n",
    "                sleep(.1)\n",
    "        return df\n",
    "\n",
    "    # Extracts text and submission datetime from document link\n",
    "    def extract_text(link):\n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "            #Parse 8-K document\n",
    "            filing = BeautifulSoup(r.content,\"html5lib\",from_encoding=\"ascii\")\n",
    "            #Extract datetime\n",
    "            try:\n",
    "                submission_dt = filing.find(\"acceptance-datetime\").string[:14]\n",
    "            except AttributeError:\n",
    "                    # Flag docs with missing data as May 1 2018 10AM\n",
    "                submission_dt = \"20180501100000\"\n",
    "            \n",
    "            submission_dt = datetime.datetime.strptime(submission_dt,\"%Y%m%d%H%M%S\")\n",
    "            #Extract HTML sections\n",
    "            for section in filing.findAll(\"html\"):\n",
    "                try:\n",
    "                    #Remove tables\n",
    "                    for table in section(\"table\"):\n",
    "                        table.decompose()\n",
    "                    #Convert to unicode\n",
    "                    section = unicodedata.normalize(\"NFKD\",section.text)\n",
    "                    section = section.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"/s\",\" \").replace(\"\\'\",\"'\")            \n",
    "                except AttributeError:\n",
    "                    section = str(section.encode('utf-8'))\n",
    "            filing = \"\".join((section))\n",
    "        except requests.exceptions.ConnectionError:\n",
    "                sleep(10)\n",
    "        sleep(.1)\n",
    "\n",
    "        return filing, submission_dt\n",
    "\n",
    "    def extract_item_no(document):\n",
    "        pattern = re.compile(\"Item+ +\\d+[\\:,\\.]+\\d+\\d\")\n",
    "        item_list = re.findall(pattern,document)\n",
    "        return item_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get S&P 500 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>3M</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>Saint Paul, Minnesota</td>\n",
       "      <td>1976-08-09</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AOS</th>\n",
       "      <td>A. O. Smith</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Building Products</td>\n",
       "      <td>Milwaukee, Wisconsin</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>91142</td>\n",
       "      <td>1916</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>Abbott</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1964-03-31</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>AbbVie</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMD</th>\n",
       "      <td>Abiomed</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Danvers, Massachusetts</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>815094</td>\n",
       "      <td>1981</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Security SEC filings  GICS Sector         GICS Sub-Industry  \\\n",
       "Symbol                                                                   \n",
       "MMM              3M     reports  Industrials  Industrial Conglomerates   \n",
       "AOS     A. O. Smith     reports  Industrials         Building Products   \n",
       "ABT          Abbott     reports  Health Care     Health Care Equipment   \n",
       "ABBV         AbbVie     reports  Health Care           Pharmaceuticals   \n",
       "ABMD        Abiomed     reports  Health Care     Health Care Equipment   \n",
       "\n",
       "          Headquarters Location Date first added      CIK      Founded  \\\n",
       "Symbol                                                                   \n",
       "MMM       Saint Paul, Minnesota       1976-08-09    66740         1902   \n",
       "AOS        Milwaukee, Wisconsin       2017-07-26    91142         1916   \n",
       "ABT     North Chicago, Illinois       1964-03-31     1800         1888   \n",
       "ABBV    North Chicago, Illinois       2012-12-31  1551152  2013 (1888)   \n",
       "ABMD     Danvers, Massachusetts       2018-05-31   815094         1981   \n",
       "\n",
       "       GICS Sub Industry  \n",
       "Symbol                    \n",
       "MMM          Industrials  \n",
       "AOS          Industrials  \n",
       "ABT          Health Care  \n",
       "ABBV         Health Care  \n",
       "ABMD         Health Care  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get table of the S&P 500 tickers, CIK, and industry from Wikipedia\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "cik_df = pd.read_html(wiki_url,header=0,index_col=0)[0]\n",
    "cik_df['GICS Sector'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df['GICS Sub Industry'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsapi import NewsApiClient\n",
    "load_dotenv()\n",
    "newsapi = NewsApiClient(api_key=os.environ[\"NEWS_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = newsapi.get_everything(\n",
    "    q=\"S&P 500\",\n",
    "    language=\"en\",\n",
    "    page_size=100,\n",
    "    sort_by=\"relevancy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>Feb 11 - Welcome to the home for real-time cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.6249</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.876</td>\n",
       "      <td>Posted \\r\\nWall Street's main indexes fell on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1531</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954</td>\n",
       "      <td>There are plenty of solid reasons why investor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.852</td>\n",
       "      <td>Feb 9 - Welcome to the home for real-time cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.849</td>\n",
       "      <td>Feb 10 (Reuters) - Futures tracking the S&amp;amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.856</td>\n",
       "      <td>Feb 11 - Welcome to the home for real-time cov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.914</td>\n",
       "      <td>NEW YORK (Reuters) - The S&amp;amp;P 500 index end...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.848</td>\n",
       "      <td>Feb 7 - Welcome to the home for real-time cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.5859</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.873</td>\n",
       "      <td>Feb 14 (Reuters) - Goldman Sachs has tempered ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NEW YORK, Feb 22 (Reuters) - The S&amp;amp;P 500's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound  Positive  Negative  Neutral  \\\n",
       "0    0.6369     0.148     0.000    0.852   \n",
       "1   -0.6249     0.000     0.124    0.876   \n",
       "2    0.1531     0.046     0.000    0.954   \n",
       "3    0.6369     0.148     0.000    0.852   \n",
       "4    0.6908     0.151     0.000    0.849   \n",
       "5    0.6369     0.144     0.000    0.856   \n",
       "6   -0.4404     0.000     0.086    0.914   \n",
       "7    0.6369     0.152     0.000    0.848   \n",
       "8   -0.5859     0.000     0.127    0.873   \n",
       "9    0.0000     0.000     0.000    1.000   \n",
       "\n",
       "                                                Text  \n",
       "0  Feb 11 - Welcome to the home for real-time cov...  \n",
       "1  Posted \\r\\nWall Street's main indexes fell on ...  \n",
       "2  There are plenty of solid reasons why investor...  \n",
       "3  Feb 9 - Welcome to the home for real-time cove...  \n",
       "4  Feb 10 (Reuters) - Futures tracking the S&amp;...  \n",
       "5  Feb 11 - Welcome to the home for real-time cov...  \n",
       "6  NEW YORK (Reuters) - The S&amp;P 500 index end...  \n",
       "7  Feb 7 - Welcome to the home for real-time cove...  \n",
       "8  Feb 14 (Reuters) - Goldman Sachs has tempered ...  \n",
       "9  NEW YORK, Feb 22 (Reuters) - The S&amp;P 500's...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the S&p 500 sentiment scores DataFrame\n",
    "sentiments = []\n",
    "\n",
    "for article in headlines[\"articles\"]:\n",
    "    try:\n",
    "        \n",
    "        text = article[\"content\"]\n",
    "        date = article[\"publishedAt\"][:10]\n",
    "        sentiment = analyzer.polarity_scores(text)\n",
    "        compound = sentiment[\"compound\"]\n",
    "        pos = sentiment[\"pos\"]\n",
    "        neu = sentiment[\"neu\"]\n",
    "        neg = sentiment[\"neg\"]\n",
    "        \n",
    "        sentiments.append({\n",
    "            \n",
    "            \n",
    "            \"Compound\": compound,\n",
    "            \"Positive\": pos,\n",
    "            \"Negative\": neg,\n",
    "            \"Neutral\": neu,\n",
    "            \"Text\": text\n",
    "            \n",
    "        })\n",
    "        \n",
    "    except AttributeError:\n",
    "        pass\n",
    "    \n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(sentiments)\n",
    "\n",
    "# Reorder DataFrame columns\n",
    "cols = [\"Compound\", \"Positive\", \"Negative\", \"Neutral\",\"Text\"]\n",
    "df = df[cols]\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.168539</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.054140</td>\n",
       "      <td>0.844230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.532687</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>0.069649</td>\n",
       "      <td>0.082521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.836000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.307000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.118000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.849500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.636900</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.111250</td>\n",
       "      <td>0.873750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.282000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Compound    Positive    Negative     Neutral\n",
       "count  100.000000  100.000000  100.000000  100.000000\n",
       "mean     0.168539    0.101600    0.054140    0.844230\n",
       "std      0.532687    0.081072    0.069649    0.082521\n",
       "min     -0.836000    0.000000    0.000000    0.633000\n",
       "25%     -0.307000    0.000000    0.000000    0.791250\n",
       "50%      0.261600    0.118000    0.000000    0.849500\n",
       "75%      0.636900    0.152000    0.111250    0.873750\n",
       "max      0.910000    0.287000    0.282000    1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Expand the default stopwords list if necessary\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
